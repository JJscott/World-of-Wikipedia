---
title:  "Concept"
authors: [josh, ben]
tags: mddn442
---

What do you do when you're given a project with a topic scope as generic as 'time'? After a lengthy debate and many possible ideas my collegue Ben and I have decide to build a visualistion of data gathered from Wikipedia, taking a look at the interations between geolocations, dates, and ip addresses of anonymous editors over time. Introducting the World of Wikipedia!  

![World of Wikipedia!][wow-logo]  

Most wikipedia entries that relate to an event in human history have both a geographic location and a time they happened. Even may be wars that take place, monuments that have been built or famous people that were born (vague location). The first challenge however is to "aquire" a copy of Wikipedia for parsing. Luckily Wikipedia [makes this easy][wiki-download] for us by providing multiple ways of downloading exactly what we need. We've downloaded the latest english Wikipedia dump without images; a 10GB zip file that extracts into a single 45GB .xml file. Holy damn!  


Parsing raw data aside, being able to visualise this information is trivial so we aren't going to stop there. There is a wealth of meta-data on each of the pages with geolocations, mostly page edits. Being able to visualise the edits over time by tracking anonymous ip to another geolocation would give us a cross reference as to where someone is editing the page from. From this we could examine wether people closer to the geolcation described in the article have more or less influence in it's information than people that live further away.  

![Kotoku-in][wiki-buddha-pic]  

As an example, imagine the ["Great Buddha" Kotoku-in][wiki-buddha] in the city of Kamakura in Kanagawa Prefecture, Japan. The statue is very popular tourist location that has great ties to the history of Japan, but who would add to and update it's wikipedia page? The tourists that visit it? The historians in Japan? Researchers on the other side of the world? The local residents? It's this scenario that our visualisation could provide without doing a complex analysis.  

There are other visualistations that we could possibly do with the data that we have at hand, but for now we are focused on the first step which is parsing the Wikipedia raw dump, into something a little more usefull. Will be detailing more about that in future posts.  

[wow-logo]: http://i.imgur.com/rXg1yRU.png
[wiki-download]: http://en.wikipedia.org/wiki/Wikipedia:Database_download
[wiki-buddha]: http://en.wikipedia.org/wiki/K%C5%8Dtoku-in
[wiki-buddha-pic]: http://i.imgur.com/0n7SZTd.jpg
